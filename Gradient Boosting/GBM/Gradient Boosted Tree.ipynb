{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2b13e5",
   "metadata": {},
   "source": [
    "# Hard coded Gradient Boosted Tree for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c41c5",
   "metadata": {},
   "source": [
    "### This is the kaggle dataset link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdefc0a",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/datasets/abhishek14398/salary-dataset-simple-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca107e",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38149932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd485888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "df = pd.read_csv('Salary_dataset.csv')\n",
    "df = df.drop(df.columns[0], axis=1) # Drop id Column\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6baba0",
   "metadata": {},
   "source": [
    "### GBT function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a719e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBTRegression(X, y, learning_rate, num_iters):\n",
    "    '''\n",
    "    F_x :             Cumulative prediction at any step in gradient boosting\n",
    "    residuals:        The difference between the actual values and the current predictions\n",
    "    h_x:              The prediction from the new tree fitted to the residuals at each boosting step\n",
    "    learning_rate:    A scaling factor applied to the predictions of each new tree, controlling how much each tree contributes to the final model\n",
    "    '''\n",
    "    F_x = np.mean(y) * np.ones_like(y)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        residuals = y - F_x\n",
    "        h_x = residuals \n",
    "        F_x = F_x + learning_rate*h_x\n",
    "    \n",
    "    return F_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb443c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "0      39344.0\n",
      "1      46206.0\n",
      "2      37732.0\n",
      "3      43526.0\n",
      "4      39892.0\n",
      "5      56643.0\n",
      "6      60151.0\n",
      "7      54446.0\n",
      "8      64446.0\n",
      "9      57190.0\n",
      "10     63219.0\n",
      "11     55795.0\n",
      "12     56958.0\n",
      "13     57082.0\n",
      "14     61112.0\n",
      "15     67939.0\n",
      "16     66030.0\n",
      "17     83089.0\n",
      "18     81364.0\n",
      "19     93941.0\n",
      "20     91739.0\n",
      "21     98274.0\n",
      "22    101303.0\n",
      "23    113813.0\n",
      "24    109432.0\n",
      "25    105583.0\n",
      "26    116970.0\n",
      "27    112636.0\n",
      "28    122392.0\n",
      "29    121873.0\n",
      "Name: Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_iters = 1000\n",
    "y_pred = GBTRegression(X, y, learning_rate, num_iters)\n",
    "print(f\"Predictions:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ded38ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.117582368135751e-21\n",
      "R² Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fab73b",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree for Regression (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7d402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a37753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=10000,    # Number of boosting stages\n",
    "    learning_rate=0.1,   \n",
    "    max_depth=10,         # Maximum depth of the individual regression estimators\n",
    "    random_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fa0acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 69191443.33329761\n",
      "R² Score: 0.8927767929694809\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61fb3d",
   "metadata": {},
   "source": [
    "# Hard coded Gradient Boosted Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a7d973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction Log-Odds (F_0): [0.69314718 0.69314718 0.69314718]\n",
      "\n",
      "Iteration 1\n",
      "Probabilities: [0.66666667 0.66666667 0.66666667]\n",
      "Pseudo-Residuals: [-0.66666667  0.33333333  0.33333333]\n",
      "Updated Log-Odds Prediction (F_1): [0.62648051 0.72648051 0.72648051]\n",
      "\n",
      "Iteration 2\n",
      "Probabilities: [0.651691   0.67403247 0.67403247]\n",
      "Pseudo-Residuals: [-0.651691    0.32596753  0.32596753]\n",
      "Updated Log-Odds Prediction (F_2): [0.56131141 0.75907727 0.75907727]\n",
      "\n",
      "Iteration 3\n",
      "Probabilities: [0.63675592 0.68115336 0.68115336]\n",
      "Pseudo-Residuals: [-0.63675592  0.31884664  0.31884664]\n",
      "Updated Log-Odds Prediction (F_3): [0.49763582 0.79096193 0.79096193]\n",
      "\n",
      "Final Predicted Probabilities: [0.62190358 0.68803784 0.68803784]\n",
      "Final Binary Predictions: [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "X = np.array([1, 2, 3])  # Input features\n",
    "y = np.array([0, 1, 1])  # Binary target values (0 or 1)\n",
    "learning_rate = 0.1\n",
    "num_iterations = 3\n",
    "\n",
    "\n",
    "initial_log_odds = np.log(np.mean(y) / (1 - np.mean(y)))\n",
    "F_x = initial_log_odds * np.ones_like(y)  # Initial prediction log-odds\n",
    "print(f\"Initial Prediction Log-Odds (F_0): {F_x}\")\n",
    "\n",
    "# Sigmoid function to convert log-odds to probabilities\n",
    "def sigmoid(log_odds):\n",
    "    return 1 / (1 + np.exp(-log_odds))\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    p = sigmoid(F_x)\n",
    "    residuals = y - p  \n",
    "    print(f\"\\nIteration {i+1}\")\n",
    "    print(f\"Probabilities: {p}\")\n",
    "    print(f\"Pseudo-Residuals: {residuals}\")\n",
    "    \n",
    "    h_x = residuals\n",
    "    F_x = F_x + learning_rate * h_x\n",
    "    print(f\"Updated Log-Odds Prediction (F_{i+1}): {F_x}\")\n",
    "    \n",
    "final_probabilities = sigmoid(F_x)\n",
    "final_predictions = (final_probabilities >= 0.5).astype(int)  # Convert to binary predictions\n",
    "print(\"\\nFinal Predicted Probabilities:\", final_probabilities)\n",
    "print(\"Final Binary Predictions:\", final_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf8283",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree for Classification (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1b48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b97faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1], [2], [3]]) # X needs to be 2D array for the sklearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f2cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=3,       \n",
    "    learning_rate=0.1,    \n",
    "    max_depth=1,          \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cca18bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71bfc0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Binary Predictions: [0 1 1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"\\nFinal Binary Predictions:\", y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
